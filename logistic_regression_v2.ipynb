{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Goldsmiths University of London\n",
    "### Author....: Carlos Manuel de Oliveira Alves\n",
    "### Student...: cdeol003\n",
    "### Created...: 11/02/2023\n",
    "### FYP.......: NeuroCredit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the dataset\n",
    "dataset = pd.read_csv('data.csv')\n",
    "\n",
    "# Split the dataset into independent and dependent variables\n",
    "\n",
    "# Select all the columns except the last one as the independent variables vector\n",
    "X = dataset.iloc[:, :-1].values\n",
    "\n",
    "# Select the last column as the dependent variable vector\n",
    "y = dataset.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Poor' 'Self-Employed' 'None' 'Fair' 'Auto' 'Judgement'\n",
      "  'Debt Consolidation' 30971 11969 78 21 0 5 0 135 18627 25 4648 4719]\n",
      " ['Poor' 'Unemployed' 'Investment' 'Excellent' 'Mortgage' 'Collection'\n",
      "  'Home Improvement' 19120 45396 81 92 0 2 1 19857 11996 58 2657 19366]\n",
      " ['Excellent' 'Unemployed' 'House' 'Poor' 'Other' 'Bankruptcy'\n",
      "  'Debt Consolidation' 48687 18880 73 27 0 3 1 17501 18074 30 2487 15500]\n",
      " ['Fair' 'Unemployed' 'Car' 'Good' 'Other' 'Tax Lien' 'Home Improvement'\n",
      "  40997 11527 6 19 3 3 4 9376 5073 60 3100 12380]\n",
      " ['Good' 'Unemployed' 'House' 'Excellent' 'Personal' 'None' 'Business'\n",
      "  35485 27016 33 49 5 2 3 18960 14542 99 1596 7946]]\n"
     ]
    }
   ],
   "source": [
    "# Print first 5 rows with the independent variables vector\n",
    "print(X[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Rejected' 'Rejected' 'Rejected' 'Rejected' 'Rejected']\n"
     ]
    }
   ],
   "source": [
    "# Print first 5 rows with the dependent variable vector\n",
    "print(y[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "credit_history                                     0\n",
      "employment_status                                  0\n",
      "collateral                                         0\n",
      "payment_history                                    0\n",
      "type_of_credit_accounts                            0\n",
      "public_records_and_collections                     0\n",
      "purpose_of_loan                                    0\n",
      "income                                             0\n",
      "assets_value                                       0\n",
      "debt_to_income_ratio                               0\n",
      "length_of_credit_history                           0\n",
      "number_of_credit_inquiries                         0\n",
      "number_of_credit_accounts                          0\n",
      "number_of_credit_accounts_opened_last_12_months    0\n",
      "current_balance_of_credit_accounts                 0\n",
      "total_credit_limit                                 0\n",
      "total_credit_utilization                           0\n",
      "loan_amount                                        0\n",
      "saving_account_balance                             0\n",
      "approval_status                                    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Print the missing values in the dataset\n",
    "print(dataset.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the categorical data\n",
    "\n",
    "# Import the library for encoding the categorical data\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Import the library for one hot encoding the categorical data\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Create an object of the ColumnTransformer class\n",
    "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [0,1,2,3,4,5,6])], remainder='passthrough')\n",
    "\n",
    "# Encoding the independent variables vector\n",
    "X = np.array(ct.fit_transform(X))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0 0.0 0.0 1.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 1.0 0.0 0.0 1.0\n",
      "  0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 30971 11969\n",
      "  78 21 0 5 0 135 18627 25 4648 4719]\n",
      " [0.0 0.0 0.0 1.0 0.0 0.0 1.0 0.0 0.0 1.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0\n",
      "  1.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 19120 45396\n",
      "  81 92 0 2 1 19857 11996 58 2657 19366]\n",
      " [1.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0\n",
      "  0.0 1.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 48687 18880\n",
      "  73 27 0 3 1 17501 18074 30 2487 15500]\n",
      " [0.0 1.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0\n",
      "  0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 1.0 0.0 40997 11527\n",
      "  6 19 3 3 4 9376 5073 60 3100 12380]\n",
      " [0.0 0.0 1.0 0.0 0.0 0.0 1.0 0.0 1.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0\n",
      "  0.0 0.0 1.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 35485 27016\n",
      "  33 49 5 2 3 18960 14542 99 1596 7946]]\n"
     ]
    }
   ],
   "source": [
    "# Print first 5 rows with the independent variables vector\n",
    "print(X[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "19\n"
     ]
    }
   ],
   "source": [
    "# Print all the index numbers of the categorical columns\n",
    "print(dataset.columns.get_loc(\"credit_history\"))\n",
    "print(dataset.columns.get_loc(\"employment_status\"))\n",
    "print(dataset.columns.get_loc(\"collateral\"))\n",
    "print(dataset.columns.get_loc(\"payment_history\"))\n",
    "print(dataset.columns.get_loc(\"type_of_credit_accounts\"))\n",
    "print(dataset.columns.get_loc(\"public_records_and_collections\"))\n",
    "print(dataset.columns.get_loc(\"purpose_of_loan\"))\n",
    "print(dataset.columns.get_loc(\"approval_status\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['credit_history', 'employment_status', 'collateral', 'payment_history',\n",
      "       'type_of_credit_accounts', 'public_records_and_collections',\n",
      "       'purpose_of_loan', 'approval_status'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Print all the categorical columns in the dataset\n",
    "print(dataset.select_dtypes(include=['object']).columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding the dependent variable vector\n",
    "\n",
    "# Import the library for encoding the categorical data\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Create an object of the LabelEncoder class\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Encoding the dependent variable vector\n",
    "y = le.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "# Print first 5 rows with the dependent variable vector after encoding\n",
    "print(y[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and test sets\n",
    "\n",
    "# Import the library for splitting the dataset into training and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0 0.0 0.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0\n",
      "  0.0 0.0 0.0 1.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 36933 32921\n",
      "  12 23 5 2 1 12728 4417 33 1673 17013]\n",
      " [1.0 0.0 0.0 0.0 0.0 1.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0\n",
      "  0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0 0.0 0.0 0.0 42898 41738\n",
      "  50 21 3 5 0 10581 1886 7 4918 5022]\n",
      " [0.0 0.0 1.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0\n",
      "  0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 1.0 0.0 0.0 12434 31547\n",
      "  32 80 0 3 2 11553 16452 33 3848 6464]\n",
      " [1.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 1.0 0.0 0.0\n",
      "  0.0 0.0 1.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 18089 18164\n",
      "  78 44 1 3 5 4784 12920 59 1886 7582]\n",
      " [1.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 1.0 1.0\n",
      "  0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 15341 47687\n",
      "  87 62 2 0 3 11877 1632 22 2821 11378]]\n"
     ]
    }
   ],
   "source": [
    "# Print first 5 rows from the X training set\n",
    "print(X_train[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0 0.0 1.0 0.0 0.0 1.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0\n",
      "  0.0 0.0 0.0 1.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 14670 28260\n",
      "  79 29 4 2 0 13341 1874 22 2942 6405]\n",
      " [0.0 0.0 0.0 1.0 0.0 1.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 1.0\n",
      "  0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 20346 20062\n",
      "  90 21 1 5 0 19669 2938 59 2848 9107]\n",
      " [0.0 0.0 1.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0\n",
      "  0.0 0.0 0.0 1.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 46322 40877\n",
      "  60 94 4 3 4 1829 2499 0 3514 3353]\n",
      " [1.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0\n",
      "  0.0 0.0 0.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 41282 13191\n",
      "  38 54 5 3 3 15807 5887 92 3152 19206]\n",
      " [0.0 0.0 0.0 1.0 1.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0\n",
      "  0.0 0.0 0.0 1.0 0.0 0.0 1.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 22875 19554\n",
      "  38 83 2 2 5 12738 8179 52 2228 17945]]\n"
     ]
    }
   ],
   "source": [
    "# Print first 5 rows from the X test set\n",
    "print(X_test[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "# Print first 5 rows from the Y training set\n",
    "print(y_train[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "# Print first 5 rows from the Y test set\n",
    "print(y_test[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'assign'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[92], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m X_train_num \u001b[39m=\u001b[39m X_train[:, [\u001b[39m1\u001b[39m, \u001b[39m4\u001b[39m, \u001b[39m5\u001b[39m, \u001b[39m7\u001b[39m, \u001b[39m8\u001b[39m, \u001b[39m9\u001b[39m, \u001b[39m10\u001b[39m, \u001b[39m12\u001b[39m, \u001b[39m13\u001b[39m, \u001b[39m14\u001b[39m, \u001b[39m16\u001b[39m, \u001b[39m17\u001b[39m, \u001b[39m18\u001b[39m]]\n\u001b[0;32m      9\u001b[0m \u001b[39m# Transform the training set using the fitted scaler for numerical columns with index 1, 4, 5, 7, 8, 9, 10, 12, 13, 14, 16, 17, and 18\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m X_train_num \u001b[39m=\u001b[39m X_train_num\u001b[39m.\u001b[39;49massign(scaled\u001b[39m=\u001b[39mscaler\u001b[39m.\u001b[39mfit_transform(X_train_num))\n\u001b[0;32m     12\u001b[0m \u001b[39m# Transform the test set using the fitted scaler for numerical columns with index 1, 4, 5, 7, 8, 9, 10, 12, 13, 14, 16, 17, and 18\u001b[39;00m\n\u001b[0;32m     13\u001b[0m X_test_num \u001b[39m=\u001b[39m X_test[:, [\u001b[39m1\u001b[39m, \u001b[39m4\u001b[39m, \u001b[39m5\u001b[39m, \u001b[39m7\u001b[39m, \u001b[39m8\u001b[39m, \u001b[39m9\u001b[39m, \u001b[39m10\u001b[39m, \u001b[39m12\u001b[39m, \u001b[39m13\u001b[39m, \u001b[39m14\u001b[39m, \u001b[39m16\u001b[39m, \u001b[39m17\u001b[39m, \u001b[39m18\u001b[39m]]\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'assign'"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Create an instance of the StandardScaler class\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Select numerical columns with index 1, 4, 5, 7, 8, 9, 10, 12, 13, 14, 16, 17, and 18\n",
    "X_train_num = X_train[:, [1, 4, 5, 7, 8, 9, 10, 12, 13, 14, 16, 17, 18]]\n",
    "\n",
    "# Transform the training set using the fitted scaler for numerical columns with index 1, 4, 5, 7, 8, 9, 10, 12, 13, 14, 16, 17, and 18\n",
    "X_train_num = X_train_num.assign(scaled=scaler.fit_transform(X_train_num))\n",
    "\n",
    "# Transform the test set using the fitted scaler for numerical columns with index 1, 4, 5, 7, 8, 9, 10, 12, 13, 14, 16, 17, and 18\n",
    "X_test_num = X_test[:, [1, 4, 5, 7, 8, 9, 10, 12, 13, 14, 16, 17, 18]]\n",
    "X_test_num = X_test_num.assign(scaled=scaler.transform(X_test_num))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "07399a9b4a62e4c2eb93a877b8941afe4222eac8f395849197d7e356d4348282"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
